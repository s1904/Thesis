{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Brain MRI 3D-CNN Training\n",
        "Upload your brain_mri_data folder and mri_dataset.csv to Google Drive first"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import torch\n",
        "print(f'CUDA available: {torch.cuda.is_available()}')\n",
        "if torch.cuda.is_available():\n",
        "    print(f'GPU: {torch.cuda.get_device_name(0)}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "!pip install nibabel -q"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import os\n",
        "DRIVE_FOLDER = '/content/drive/MyDrive/Thesis'\n",
        "DATA_DIR = os.path.join(DRIVE_FOLDER, 'brain_mri_data')\n",
        "CSV_PATH = os.path.join(DRIVE_FOLDER, 'mri_dataset.csv')\n",
        "MODEL_PATH = os.path.join(DRIVE_FOLDER, 'brain_model.pth')\n",
        "print(f'Data exists: {os.path.exists(DATA_DIR)}')\n",
        "print(f'CSV exists: {os.path.exists(CSV_PATH)}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import nibabel as nib\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import torch.nn.functional as F\n",
        "from scipy import ndimage\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "DEVICE = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "class BrainMRIDataset(Dataset):\n",
        "    def __init__(self, data_dir, csv_path, augment=False, target_shape=(128, 128, 128)):\n",
        "        self.data_dir = data_dir\n",
        "        self.augment = augment\n",
        "        self.target_shape = target_shape\n",
        "        self.file_paths = []\n",
        "        self.labels = []\n",
        "        df = pd.read_csv(csv_path)\n",
        "        print(f'CSV has {len(df)} rows')\n",
        "        print(f'Target shape for all images: {target_shape}')\n",
        "        matched = 0\n",
        "        for f in os.listdir(data_dir):\n",
        "            if f.endswith('.nii') or f.endswith('.nii.gz'):\n",
        "                parts = f.split('_')\n",
        "                if len(parts) >= 2:\n",
        "                    age_from_file = int(parts[0])\n",
        "                    gender_from_file = parts[1]\n",
        "                    tissue = 'GM' if 'wrp1' in f else 'WM'\n",
        "                    gender_full = 'Female' if gender_from_file == 'F' else 'Male'\n",
        "                    match = df[(df['age'] == age_from_file) & (df['gender'] == gender_full) & (df['tissue'] == tissue)]\n",
        "                    if not match.empty:\n",
        "                        row = match.iloc[0]\n",
        "                        age = row['age'] / 100.0\n",
        "                        sex = 0 if row['gender'] == 'Female' else 1\n",
        "                        tissue_label = 0 if tissue == 'GM' else 1\n",
        "                        self.file_paths.append(os.path.join(data_dir, f))\n",
        "                        self.labels.append([age, sex, tissue_label])\n",
        "                        matched += 1\n",
        "        print(f'Matched {matched} out of {len(os.listdir(data_dir))} files')\n",
        "        print(f'Found {len(self.file_paths)} samples')\n",
        "    def __len__(self):\n",
        "        return len(self.file_paths)\n",
        "    def __getitem__(self, idx):\n",
        "        img = nib.load(self.file_paths[idx])\n",
        "        data = img.get_fdata().astype(np.float32)\n",
        "        original_shape = data.shape\n",
        "        zoom_factors = [t / o for t, o in zip(self.target_shape, original_shape)]\n",
        "        data = ndimage.zoom(data, zoom_factors, order=1)\n",
        "        data = np.clip(data, np.percentile(data, 1), np.percentile(data, 99))\n",
        "        data_min = data.min()\n",
        "        data_max = data.max()\n",
        "        if data_max > data_min:\n",
        "            data = (data - data_min) / (data_max - data_min)\n",
        "        else:\n",
        "            data = data - data_min\n",
        "        if self.augment and np.random.rand() > 0.5:\n",
        "            angle = np.random.uniform(-5, 5)\n",
        "            data = ndimage.rotate(data, angle, axes=(0, 1), reshape=False, order=1)\n",
        "            if np.random.rand() > 0.5:\n",
        "                data = np.flip(data, axis=0).copy()\n",
        "        data = np.expand_dims(data, axis=0)\n",
        "        return torch.FloatTensor(data), torch.FloatTensor(self.labels[idx])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "class BrainCNN3D(nn.Module):\n",
        "    def __init__(self, dropout_rate=0.3):\n",
        "        super(BrainCNN3D, self).__init__()\n",
        "        self.conv1 = nn.Conv3d(1, 32, kernel_size=3, padding=1)\n",
        "        self.bn1 = nn.BatchNorm3d(32)\n",
        "        self.pool1 = nn.MaxPool3d(2)\n",
        "        self.conv2 = nn.Conv3d(32, 64, kernel_size=3, padding=1)\n",
        "        self.bn2 = nn.BatchNorm3d(64)\n",
        "        self.pool2 = nn.MaxPool3d(2)\n",
        "        self.conv3 = nn.Conv3d(64, 128, kernel_size=3, padding=1)\n",
        "        self.bn3 = nn.BatchNorm3d(128)\n",
        "        self.pool3 = nn.MaxPool3d(2)\n",
        "        self.conv4 = nn.Conv3d(128, 256, kernel_size=3, padding=1)\n",
        "        self.bn4 = nn.BatchNorm3d(256)\n",
        "        self.pool4 = nn.MaxPool3d(2)\n",
        "        self.global_pool = nn.AdaptiveAvgPool3d(1)\n",
        "        self.fc1 = nn.Linear(256, 128)\n",
        "        self.dropout1 = nn.Dropout(dropout_rate)\n",
        "        self.age_head = nn.Linear(128, 1)\n",
        "        self.sex_head = nn.Linear(128, 1)\n",
        "        self.tissue_head = nn.Linear(128, 1)\n",
        "    def forward(self, x):\n",
        "        x = self.pool1(F.relu(self.bn1(self.conv1(x))))\n",
        "        x = self.pool2(F.relu(self.bn2(self.conv2(x))))\n",
        "        x = self.pool3(F.relu(self.bn3(self.conv3(x))))\n",
        "        x = self.pool4(F.relu(self.bn4(self.conv4(x))))\n",
        "        x = self.global_pool(x)\n",
        "        x = x.view(x.size(0), -1)\n",
        "        x = F.relu(self.fc1(x))\n",
        "        x = self.dropout1(x)\n",
        "        age = self.age_head(x)\n",
        "        sex = self.sex_head(x)\n",
        "        tissue = self.tissue_head(x)\n",
        "        return age, sex, tissue"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "EPOCHS = 200\n",
        "BATCH_SIZE = 4\n",
        "LR = 0.0001\n",
        "TARGET_SHAPE = (128, 128, 128)\n",
        "print('Creating datasets...')\n",
        "train_full = BrainMRIDataset(DATA_DIR, CSV_PATH, augment=True, target_shape=TARGET_SHAPE)\n",
        "val_full = BrainMRIDataset(DATA_DIR, CSV_PATH, augment=False, target_shape=TARGET_SHAPE)\n",
        "train_size = int(0.8 * len(train_full))\n",
        "indices = list(range(len(train_full)))\n",
        "np.random.seed(42)\n",
        "np.random.shuffle(indices)\n",
        "train_idx = indices[:train_size]\n",
        "val_idx = indices[train_size:]\n",
        "train_ds = torch.utils.data.Subset(train_full, train_idx)\n",
        "val_ds = torch.utils.data.Subset(val_full, val_idx)\n",
        "train_loader = DataLoader(train_ds, batch_size=BATCH_SIZE, shuffle=True, num_workers=0)\n",
        "val_loader = DataLoader(val_ds, batch_size=BATCH_SIZE, shuffle=False, num_workers=0)\n",
        "print(f'Train: {len(train_ds)}, Val: {len(val_ds)}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "model = BrainCNN3D(dropout_rate=0.3).to(DEVICE)\n",
        "age_crit = nn.MSELoss()\n",
        "sex_crit = nn.BCEWithLogitsLoss()\n",
        "tissue_crit = nn.BCEWithLogitsLoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=LR, weight_decay=1e-5)\n",
        "scheduler = optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=EPOCHS, eta_min=1e-6)\n",
        "print('Model ready')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from tqdm.notebook import tqdm\n",
        "best_loss = float('inf')\n",
        "for epoch in range(EPOCHS):\n",
        "    model.train()\n",
        "    train_loss = 0.0\n",
        "    for batch_data, batch_labels in tqdm(train_loader, desc=f'Epoch {epoch+1}/{EPOCHS}', leave=False):\n",
        "        batch_data = batch_data.to(DEVICE)\n",
        "        batch_labels = batch_labels.to(DEVICE)\n",
        "        optimizer.zero_grad()\n",
        "        age_pred, sex_pred, tissue_pred = model(batch_data)\n",
        "        age_loss = age_crit(age_pred.squeeze(), batch_labels[:, 0])\n",
        "        sex_loss = sex_crit(sex_pred.squeeze(), batch_labels[:, 1])\n",
        "        tissue_loss = tissue_crit(tissue_pred.squeeze(), batch_labels[:, 2])\n",
        "        loss = age_loss + sex_loss + tissue_loss\n",
        "        loss.backward()\n",
        "        torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\n",
        "        optimizer.step()\n",
        "        train_loss += loss.item()\n",
        "    train_loss /= len(train_loader)\n",
        "    model.eval()\n",
        "    val_loss = 0.0\n",
        "    age_errors = []\n",
        "    sex_correct = 0\n",
        "    tissue_correct = 0\n",
        "    total = 0\n",
        "    with torch.no_grad():\n",
        "        for batch_data, batch_labels in val_loader:\n",
        "            batch_data = batch_data.to(DEVICE)\n",
        "            batch_labels = batch_labels.to(DEVICE)\n",
        "            age_pred, sex_pred, tissue_pred = model(batch_data)\n",
        "            age_loss = age_crit(age_pred.squeeze(), batch_labels[:, 0])\n",
        "            sex_loss = sex_crit(sex_pred.squeeze(), batch_labels[:, 1])\n",
        "            tissue_loss = tissue_crit(tissue_pred.squeeze(), batch_labels[:, 2])\n",
        "            loss = age_loss + sex_loss + tissue_loss\n",
        "            val_loss += loss.item()\n",
        "            age_errors.extend((torch.abs(age_pred.squeeze() - batch_labels[:, 0]) * 100).cpu().numpy())\n",
        "            sex_correct += ((torch.sigmoid(sex_pred.squeeze()) > 0.5) == batch_labels[:, 1]).sum().item()\n",
        "            tissue_correct += ((torch.sigmoid(tissue_pred.squeeze()) > 0.5) == batch_labels[:, 2]).sum().item()\n",
        "            total += batch_labels.size(0)\n",
        "    val_loss /= len(val_loader)\n",
        "    age_mae = np.mean(age_errors)\n",
        "    sex_acc = 100 * sex_correct / total\n",
        "    tissue_acc = 100 * tissue_correct / total\n",
        "    if (epoch + 1) % 10 == 0 or epoch == 0:\n",
        "        print(f'Epoch {epoch+1}/{EPOCHS}: Loss={val_loss:.4f}, Age MAE={age_mae:.2f}, Sex={sex_acc:.1f}%, Tissue={tissue_acc:.1f}%')\n",
        "    if val_loss < best_loss:\n",
        "        best_loss = val_loss\n",
        "        torch.save(model.state_dict(), MODEL_PATH)\n",
        "        if (epoch + 1) % 10 == 0:\n",
        "            print('  Best model saved!')\n",
        "    scheduler.step()\n",
        "print(f'Training complete! Best loss: {best_loss:.4f}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from google.colab import files\n",
        "files.download(MODEL_PATH)"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 4
}

